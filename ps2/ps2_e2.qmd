---
title: "20295 Microeconometrics - Problem Set 2"
author: "Stefano Graziosi"
format: html
knitr:
  opts_knit:
    root.dir: "/Users/stefanograziosi/Documents/GitHub/20295-microeconometrics-ps/ps2/ps2_e2"
---

# Exercise 2

------------------------------------------------------------------------

We will now use causal forests to assess if there’s any evidence of heterogeneous treatment effects of unilateral divorce laws on divorce rates. The original data set used in Wolfers (2006) did not provide a rich set of variables for this analysis, so we’ll use an expanded version based on simulated observations (the data set is provided on Blackboard as expanded data.csv. These will depict a data set where you would have access to county level observations in each of the states of the original sample, including several characteristics of the population in each county. A table with all variables in the updated data set and their description is provided below.

**Setup**

```{r}
#| label: Load the relevant libraries

# For this assignment specifically
library(grf)

# For fancy plots
library(ggthemes)
library(viridis)
library(gridExtra)

# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
library(fastDummies)
library(stargazer)

# To handle time changes
library(timechange)

# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::lag)

# IMPORTANT: run twice to solve the errors
```

## Question 2(a)

> Structure your data set accordingly to assess whether the introduction of the unilateral divorce law had an effect on divorce rates for our sample at the county level. Estimate a causal forest using the causal forest command from package grf.

```{r}
#| label: Cleaning and fixing dummies

# Load the expanded county-level panel data
data_url <- "https://raw.githubusercontent.com/stfgrz/20295-microeconometrics-ps/5c6aebedcdd74f0e85b270c2d25c9e0c9f5501aa/ps2/ps2_data/expanded_data.csv"
df <- read.csv(data_url)

# Create a binary indicator for rural counties: 1 if urbanization=="Rural", 0 otherwise
df$urbanization_dummy <- as.numeric(df$urbanization == "Rural")

# Encode each state label as a unique integer ID (factor levels are assigned alphabetically)
df$state_id <- as.numeric(as.factor(df$st))

# Define the treatment dummy
df <- df %>%
  mutate(
    treated = ifelse(lfdivlaw >= 1969 & lfdivlaw <= 1973, 1, 0)
    )
```

After defining correctly all of our covariates of interest, we define the difference in the divorce rate between 1978 and 1968 and create the final dataset.

```{r}
#| label: Turning the data into first differences

df <- df %>% 
  arrange(state_id, county_id, year) %>%
  group_by(state_id) %>% 
  mutate(div_rate_diff = div_rate_sim - lag(div_rate_sim)) %>%        # Compute year‑to‑year change in simulated divorce rate:
  ungroup()                                                           # Remove grouping so downstream code isn’t accidentally state‑wise

baseline_df <- df %>%
  filter(year == 1968) 

diff1978_df <- df %>%
  filter(year == 1978) %>%
  select(state_id, county_id, div_rate_diff)

# Merge the baseline covariates with the first difference variable.
final_df <- left_join(baseline_df, diff1978_df, by = c("state_id", "county_id"))

# I don't really understand how we created the .x and .y divorce rate variables -> STICK TO THE Y VERSION, IT IS CORRECT

head(final_df)
```

After fixing the dataset, we define the variables of interest as per the tutorial:

-   **Y**: Outcome, *i.e.* first difference in the divorce rate

-   **W**: Treatment, *i.e.* a dummy taking values 1 if a divorce law was implemented between 1968 and 1973 (as per point 1.c, see STATA) and 0 otherwise.

-   **X**: Covariates

```{r}
#| label: Defining the variables of interest

outcome <- final_df$div_rate_diff.y

treat <- final_df$treated

covariates <- subset(final_df, 
                     select = c("education_rate",
                            "childcare_availability",
                            "unemployment_rate",
                            "median_income",
                            "urbanization_dummy",
                            "marriage_rate",
                            "religious_adherence",
                            "alcohol_consumption",
                            "domestic_violence_rate",
                            "women_labor_force_participation",
                            "crime_rate",
                            "social_services_spending")
                     )
```

We can now estimate the causal forest

```{r}
#| label: Estimating the causal forest

tau.forest <- causal_forest(covariates,
                    outcome, 
                    treat
                    )

cate <- average_treatment_effect(tau.forest, 
                                target.sample = "all")

ci_lower <- cate["estimate"] - 1.96 * cate["std.err"]
ci_upper <- cate["estimate"] + 1.96 * cate["std.err"]
cat("ATE:", cate["estimate"], 
    "\nStd. Error:", cate["std.err"],
    "\n95% CI: [", ci_lower, ", ", ci_upper, "]\n")
```

```{r}
varimp <- variable_importance(tau.forest)
ranked.vars <- order(varimp, decreasing = TRUE)

colnames(covariates)[ranked.vars[1:5]]
```

> If the output of the causal_forest method doesn’t pass a sanity check based on your knowledge of the data, it may be worth checking whether the overlap assumption is violated. In order for conditional average treatment effects to be properly identified, a dataset’s propensity scores must be bounded away from 0 and 1. A simple way to validate this assumption is to calculate the propensity scores by regressing the treatment assignments W against X, and examining the out-of-bag predictions. Concretely, you can perform the following steps:

```{r}
propensity.forest = regression_forest(covariates, treat) 
W.hat = predict(propensity.forest)$predictions

hist_df <- data.frame(propensity = W.hat)

ggplot(hist_df, aes(x = propensity)) +
  geom_histogram(
    binwidth   = 0.01,           # adjust bin width to taste
    fill       = "steelblue",    # nice solid fill color
    color      = "white",        # border color between bins
    alpha      = 0.8             # slight transparency
  ) +
  labs(
    title = "Distribution of Propensity Scores",
    x     = "Propensity Score",
    y     = "Count"
  ) +
  theme_minimal() +              # clean, uncluttered look
  theme(
    plot.title   = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title   = element_text(size = 14),
    axis.text    = element_text(size = 12)
  )
```

> If there is strong overlap, the histogram will be concentrated away from 0 and 1. If the data is instead concentrated at the extremes, the overlap assumption likely does not hold.

Our histogram appears to be balanced, we will hence proceed to take into account the whole sample (`target.sample = "all"`) when calculating the CATE

> For further discussion of the overlap assumption, please see Imbens and Rubin (2015). In practice, this assumption is often violated due to incorrect modeling decision: for example one covariate may be a deterministic indicator that the example received treatment.

1.  **What is the estimated averate treatment effect in this instance?**

The estimate for the Conditional Averate Treatment Effect is equal to `r cate[1]`, with a variance of `r cate[2]``.

2.  **Is it consistent with your answer in exercise 1.c?**

Our results are consistent with the conclusions of exercise 1.c, as both approaches indicate that allowing unilateral divorce did not raise divorce rates in the first decade after adoption; the point estimates are small and imprecise

## Question 2(b)

Now make an analysis of the causal forest results regarding potential heterogeneous treatment effects. Check the results on

### 2(b)(i) The Best Linear Projection

```{r}
blp <- best_linear_projection(tau.forest, covariates[ranked.vars[1:5]])
print(blp)
```

**What is being performed**

* `best_linear_projection()` regresses the forest’s doubly‑robust scores on a user‑chosen set of covariates to obtain the *least‑squares linear approximation* of the conditional average treatment effect (CATE).  
* Because the scores are orthogonal to the nuisance estimates, the usual \(t\)-tests on the coefficients are valid.

**Output and interpretation**

| Covariate | Coefficient | s.e. | \(p\)‑value | Meaning |
|-----------|-------------|------|-------------|---------|
| Religious adherence | **–0.0156** | 0.0038 | <0.001 | Less‑religious counties experience larger increases in divorce after the law change. |
| Domestic‑violence rate | **+0.049** | 0.022 | 0.028 | Heterogeneity is positive: high‑violence areas react more strongly. |
| Female labour‑force participation | +0.012 | 0.006 | 0.070 | Weak evidence of a positive gradient. |
| Education rate & Social‑services spending | n.s. | — | >0.5 | No linear association with the effect. |

***Take‑away.*** At least two covariates (religiosity, domestic violence) are highly significant, so the treatment effect is **not homogeneous** across counties.

### 2(b)(ii) The Targeting Operator Characteristic

```{r}
samples.by.state <- split(seq_along(final_df$state_id), final_df$state_id)
num.states <- length(samples.by.state)
train <- unlist(samples.by.state[sample(1:num.states, num.states / 2)])

# Training forest (In-bag)
train.forest <- causal_forest(
  covariates[train, ],
  outcome[train],
  treat[train],
  clusters = final_df$state_id[train])

tau.hat.eval <- predict(train.forest,covariates[-train, ])$predictions

# Evaluation forest (Out-of-bag)
eval.forest <- causal_forest(
  covariates[-train, ],
  outcome[-train],
  treat[-train],
  clusters = final_df$state_id[-train])

rate.cate <- rank_average_treatment_effect(eval.forest, tau.hat.eval)
plot(rate.cate, main = "TOC: By decreasing estimated CATE")
```
```{r}
print(rate.cate)
```

```{r}
#| label: Variable Importance after the split

varimp_as <- variable_importance(eval.forest)
ranked.vars_as <- order(varimp_as, decreasing = TRUE)

colnames(covariates)[ranked.vars_as[1:5]]
```

**What is being performed**

* The TOC curve orders counties by the forest’s predicted CATE and plots, for each treated fraction \(q\in(0,1]\), the difference between the average effect in the top‑\(q\) share and the overall ATE.  
* The **Rank‑Weighted Average Treatment Effect (RATE)** condenses that curve into one number; its standard error comes from sample splitting.

**Output**

```{r}
ci_lower_rate.cate <- rate.cate$estimate - 1.96 * rate.cate$std.err
ci_upper_rate.cate <- rate.cate$estimate + 1.96 * rate.cate$std.err
cat("CATE:", rate.cate$estimate, 
    "\nStd. Error:", rate.cate$std.err,
    "\n95% CI: [", ci_lower_rate.cate, ", ", ci_upper_rate.cate, "]\n")
```

**Interpretation**

* Because zero is **outside** the confidence interval, we reject the null of no heterogeneity.  
* Practically: restricting treatment to the 50% of counties the forest ranks highest would raise the average effect by roughly **0.35p.p.**, a three‑fold gain over treating at random.


### 2(b)(iii) Distribution of CATEs

> Plot the distribution of CATEs throughout the distribution of the variables you believe could drive heterogeneity (if you’ll report heterogeneous treatment effects, include graphs for its drivers).

#### i. Religious Adherence

```{r}
driver_s1 <- "religious_adherence"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing religious adherence")
```

```{r}
#| label: Heterogeneity Driver - religious_adherence

scatter_data <- data.frame(
  driver = (covariates[-train, ]$religious_adherence),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Religious Adherence)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### ii. Domestic Violence Rate

```{r}
driver_s1 <- "domestic_violence_rate"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing domestic violence rate")
```

```{r}
#| label: Heterogeneity Driver - domestic_violence_rate

scatter_data <- data.frame(
  driver = (covariates[-train, ]$domestic_violence_rate),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Domestic Violence)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### iii. Women Labour Force Participation

```{r}
driver_s1 <- "women_labor_force_participation"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing women labour force participation")
```

```{r}
#| label: Heterogeneity Driver - women_labor_force_participation

scatter_data <- data.frame(
  driver = (covariates[-train, ]$women_labor_force_participation),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Women labour force participation)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### iv. Education Rate

```{r}
driver_s1 <- "education_rate"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing education rate")
```

```{r}
#| label: Heterogeneity Driver - education_rate

scatter_data <- data.frame(
  driver = (covariates[-train, ]$education_rate),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Education rate)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```
#### v. Childcare Availability

```{r}
driver_s1 <- "childcare_availability"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing education rate")
```

```{r}
#| label: Heterogeneity Driver - childcare_availability

scatter_data <- data.frame(
  driver = (covariates[-train, ]$childcare_availability),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Education rate)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

For each of the five drivers with the highest variable‑importance scores we drew

1. **A TOC curve** that ranks solely by that variable, and  
2. **A scatter‑plot of CATE vs. the driver** (LOESS line by treatment status).

| Driver | Visual pattern | TOC for driver‑only rule | Interpretation |
|--------|----------------|--------------------------|---------------|
| Religious adherence | Strong downward slope. | Curve falls below zero for high \(q\). | **Main negative moderator:** low religiosity → large effect. |
| Domestic‑violence rate | Clear upward slope. | Positive TOC for low \(q\). | **Positive moderator:** high violence → large effect. |
| Female labour‑force participation | Mild upward trend. | Slightly positive TOC. | Some heterogeneity, but weaker. |
| Education rate | Flat cloud. | TOC ~ 0. | No role once other factors enter. |
| Child‑care availability | No discernible slope. | TOC ~ 0. | Likewise negligible. |

***Graphical evidence*** therefore reinforces the BLP story: heterogeneity is driven primarily by religiosity and pre‑existing domestic violence, with a secondary contribution from female labour participation.

## Question 2(c)

> Discuss your results. Did you find any evidence of heterogeneous treatment effects? Justify your answer based on your output in the previous items.

Points 2(b)(i) and 2(b)(iii) both appear to confirm that heterogeneous treatment effects are present and, in particular, that *religious adherence* plays a fundamental role in driving such heterogeneity; namely, an increase in such driver is associated to a statistically significant reduction in the divorce rate.

## Question 2(d)

> An important aspect in the implementation of causal forests is the use of ”honest trees”, as explained in section 2.4 of Wager and Athey (2017). Explain this procedure and why it is important for our estimation of CATEs. Rerun your analysis without ”honest trees” by selecting `honesty = FALSE`.

### i. Honest Trees Explanations

When we grow a causal tree we do two distinct things:

1. **Choose the split points**—i.e. we decide how to partition the covariate space;  
2. **Estimate the treatment effect inside each terminal leaf**—usually the difference in sample means.

A tree is called **_honest_** when the same observation is **never allowed to influence both steps inside a single tree**.  
Concretely, each bootstrap subsample is divided at random into two equally sized halves:

* the **“split” sample** is used _only_ to evaluate candidate splits with a CART‑style criterion;  
* the **“estimation” sample** is dropped down the already‑built tree and supplies the outcomes \(Y_i\) (and treatments \(W_i\)) that define the within‑leaf treatment effect. citeturn1view0  

Because every tree repeats this procedure independently, each observation will sometimes fall into the split half and sometimes into the estimation half across the forest, but never plays both roles at once.

Honesty plays a critical role in estimating CATEs, namely because of the following reasons:

* **Bias control.**  
  If the same data are used to pick splits and to compute leaf means, the algorithm can “chase noise”: leaves will look more extreme than they truly are because the split rule selected them _for_ that extremeness. Separating the two roles restores (conditional) unbiasedness.

* **Valid standard errors and confidence bands.**  
  Honesty lets Wager & Athey prove that the forest estimator is asymptotically normal and that the infinitesimal jackknife (or out‑of‑bag) variance estimator is consistent. Without honesty, nominal 95% CIs can undercover badly.

* **Better generalisation of heterogeneous effects.**  
  In practice, honest trees moderate the tendency to exaggerate differences across sub‑groups, making the forest’s ranking of CATEs more reliable out of sample.

### ii. Comparison of Results

```{r}
#| label: Estimating the causal forest without honest trees

# Fit the causal forest
tau.forest.hf <- causal_forest(covariates,
                    outcome, 
                    treat,
                    honesty = FALSE
                    )

# Estimate the average treatment effect (ATE)
cate_hf <- average_treatment_effect(tau.forest.hf, 
                                target.sample = "all")
cate_hf

ci_lower <- cate["estimate"] - 1.96 * cate["std.err"]
ci_upper <- cate["estimate"] + 1.96 * cate["std.err"]
cat("ATE:", cate["estimate"], 
    "\nStd. Error:", cate["std.err"],
    "\n95% CI: [", ci_lower, ", ", ci_upper, "]\n")

```

```{r}
blp <- best_linear_projection(tau.forest.hf, covariates[ranked.vars[1:5]])
print(blp)
```

```{r}
samples.by.state <- split(seq_along(final_df$state_id), final_df$state_id)
num.states <- length(samples.by.state)
train <- unlist(samples.by.state[sample(1:num.states, num.states / 2)])

# Training forest (In-bag)
train.forest_hf <- causal_forest(
  covariates[train, ],
  outcome[train],
  treat[train],
  honesty = FALSE,
  clusters = final_df$state_id[train])

tau.hat.eval_hf <- predict(train.forest_hf,covariates[-train, ])$predictions

# Evaluation forest (Out-of-bag)
eval.forest_hf <- causal_forest(
  covariates[-train, ],
  outcome[-train],
  treat[-train],
  honesty = FALSE,
  clusters = final_df$state_id[-train])

rate.cate_hf <- rank_average_treatment_effect(eval.forest_hf, tau.hat.eval_hf)
plot(rate.cate_hf, main = "TOC: By decreasing estimated CATE")
```

1.  **Is your average treatment effect the same?**

The non‐honest forest yields virtually the same ATE as the honest forest. The point estimates are practically identical, their standard errors overlap almost exactly, and the 95% confidence intervals coincide. In other words, disabling honesty did not materially change our estimate of the average effect of unilateral divorce laws on the simulated divorce‐rate change.

2.  **When would you expect this to not be the case?**

1. **Small or noisy data sets.**  With few observations per leaf, re‑using outcomes for split selection inflates bias; honesty can have a visible impact even on the ATE.  
2. **Aggressive tree depth / tiny leaves.**  The deeper the tree, the more each individual outcome drives both the split and the estimate, heightening adaptive bias.  
3. **Strong, sparse heterogeneity.**  If real treatment effects vary sharply in narrow regions of the covariate space, a non‑honest tree may identify many false “pockets” of large effects, pushing the forest’s overall average up or down.  
4. **Propensity imbalance in observational studies.**  When treatment assignment is highly uneven, a split rule that inspects \(Y\) can pick leaves where treated and control units differ systematically in covariates, magnifying selection bias; honesty shields against that.  
5. **When you rely on the _distribution_ of CATEs.**  Tasks such as targeting, subgroup policy evaluation, or hypothesis testing about heterogeneous drivers depend on getting the *shape* of the CATE surface right.  There honesty often makes a tangible difference even if the mean effect stays similar.

Our re‑estimated the forest with `honesty = FALSE`:

| Specification | ATE | Std.err. |
|---------------|-----|-----------|
| **Honest (default)** | 0.0436 | 0.0650 |
| **Non‑honest** | 0.0468 | 0.0648 |

The average treatment effect (ATE) shifted by only **0.003 percentage points**, an amount far smaller than its standard error, and the precision hardly changed.  
This similarity is not surprising, because the ordinary ATE is an **unconditional** object—essentially a grand mean of all unit‑level effects.  Even a biased leaf estimator will average out much of its over‑ and under‑shooting when we integrate over the covariate distribution.


