---
title: "20295 Microeconometrics - Problem Set 2"
author: "Stefano Graziosi"
format: html
knitr:
  opts_knit:
    root.dir: "/Users/stefanograziosi/Documents/GitHub/20295-microeconometrics-ps/ps2/ps2_e2"
---

# Exercise 2

------------------------------------------------------------------------

We will now use causal forests to assess if there’s any evidence of heterogeneous treatment effects of unilateral divorce laws on divorce rates. The original data set used in Wolfers (2006) did not provide a rich set of variables for this analysis, so we’ll use an expanded version based on simulated observations (the data set is provided on Blackboard as expanded data.csv. These will depict a data set where you would have access to county level observations in each of the states of the original sample, including several characteristics of the population in each county. A table with all variables in the updated data set and their description is provided below.

**Hint**

Wolfers (2006) did not provide a rich set of variables for this analysis, so we’ll use an expanded version based on simulated observations (the data set is provided on Black- board as expanded data.csv. These will depict a data set where you would have access to county level observations in each of the states of the original sample, includ- ing several characteristics of the population in each county. A table with all variables in the updated data set and their description is provided below.

**Setup**

```{r}
#| label: Load the relevant libraries

# For this assignment specifically
library(grf)

# For fancy plots
library(ggthemes)
  # Necessary packages for viridis
  library(viridisLite)
library(viridis)
library(gridExtra)

# Packages related to tidyverse, for data manipulation
library(tidyverse) # includes (lubridate), (dplyr), (ggplot2), (tidyr), (tidyselect)
library(tinytex)
library(fastDummies)
library(stargazer)

# To handle time changes
library(timechange)

# To solve conflicts
library(conflicted)
conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::lag)

# IMPORTANT: run twice to solve the errors
```

## Question 2(a)

> Structure your data set accordingly to assess whether the introduction of the unilateral divorce law had an effect on divorce rates for our sample at the county level. Estimate a causal forest using the causal forest command from package grf.

```{r}
#| label: Cleaning and fixing dummies

# Load the expanded county-level panel data
data_url <- "https://raw.githubusercontent.com/stfgrz/20295-microeconometrics-ps/5c6aebedcdd74f0e85b270c2d25c9e0c9f5501aa/ps2/ps2_data/expanded_data.csv"
df <- read.csv(data_url)

# Create a binary indicator for rural counties: 1 if urbanization=="Rural", 0 otherwise
df$urbanization_dummy <- as.numeric(df$urbanization == "Rural")

# ncode each state label as a unique integer ID (factor levels are assigned alphabetically)
df$state_id <- as.numeric(as.factor(df$st))

# Define the treatment dummy
df <- df %>%
  mutate(
    treated = ifelse(lfdivlaw >= 1969 & lfdivlaw <= 1973, 1, 0)
    )
```

After defining correctly all of our covariates of interest, we definethe difference in the divorce rate between 1978 and 1968 and create the final dataset.

```{r}
#| label: Turning the data into first differences

df <- df %>% 
  arrange(state_id, county_id, year) %>%
  group_by(state_id) %>% 
  mutate(div_rate_diff = div_rate_sim - lag(div_rate_sim)) %>%        # Compute year‑to‑year change in simulated divorce rate:
  ungroup()                                                           # Remove grouping so downstream code isn’t accidentally state‑wise

baseline_df <- df %>%
  filter(year == 1968) 

diff1978_df <- df %>%
  filter(year == 1978) %>%
  select(state_id, county_id, div_rate_diff)

# Merge the baseline covariates with the first difference variable.
final_df <- left_join(baseline_df, diff1978_df, by = c("state_id", "county_id"))

# I don't really understand how we created the .x and .y divorce rate variables -> STICK TO THE Y VERSION, IT IS CORRECT

head(final_df)
```

After fixing the dataset, we define the variables of interest as per the tutorial:

-   **Y**: Outcome, *i.e.* first difference in the divorce rate

-   **W**: Treatment, *i.e.* a dummy taking values 1 if a divorce law was implemented between 1968 and 1973 (as per point 1.c, see STATA) and 0 otherwise.

-   **X**: Covariates

```{r}
#| label: Defining the variables of interest

outcome <- final_df$div_rate_diff.y

treat <- final_df$treated

covariates <- subset(final_df, 
                     select = c("education_rate",
                            "childcare_availability",
                            "unemployment_rate",
                            "median_income",
                            "urbanization_dummy",
                            "marriage_rate",
                            "religious_adherence",
                            "alcohol_consumption",
                            "domestic_violence_rate",
                            "women_labor_force_participation",
                            "crime_rate",
                            "social_services_spending")
                     )
```

We can now estimate the causal forest

```{r}
#| label: Estimating the causal forest

tau.forest <- causal_forest(covariates,
                    outcome, 
                    treat
                    )

cate <- average_treatment_effect(tau.forest, 
                                target.sample = "all")

ci_lower <- cate["estimate"] - 1.96 * cate["std.err"]
ci_upper <- cate["estimate"] + 1.96 * cate["std.err"]
cat("ATE:", cate["estimate"], 
    "\nStd. Error:", cate["std.err"],
    "\n95% CI: [", ci_lower, ", ", ci_upper, "]\n")
```

```{r}
varimp <- variable_importance(tau.forest)
ranked.vars <- order(varimp, decreasing = TRUE)

colnames(covariates)[ranked.vars[1:5]]
```

> If the output of the causal_forest method doesn’t pass a sanity check based on your knowledge of the data, it may be worth checking whether the overlap assumption is violated. In order for conditional average treatment effects to be properly identified, a dataset’s propensity scores must be bounded away from 0 and 1. A simple way to validate this assumption is to calculate the propensity scores by regressing the treatment assignments W against X, and examining the out-of-bag predictions. Concretely, you can perform the following steps:

```{r}
propensity.forest = regression_forest(covariates, treat) 
W.hat = predict(propensity.forest)$predictions

hist_df <- data.frame(propensity = W.hat)

ggplot(hist_df, aes(x = propensity)) +
  geom_histogram(
    binwidth   = 0.01,           # adjust bin width to taste
    fill       = "steelblue",    # nice solid fill color
    color      = "white",        # border color between bins
    alpha      = 0.8             # slight transparency
  ) +
  labs(
    title = "Distribution of Propensity Scores",
    x     = "Propensity Score",
    y     = "Count"
  ) +
  theme_minimal() +              # clean, uncluttered look
  theme(
    plot.title   = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title   = element_text(size = 14),
    axis.text    = element_text(size = 12)
  )
```

> If there is strong overlap, the histogram will be concentrated away from 0 and 1. If the data is instead concentrated at the extremes, the overlap assumption likely does not hold.

Our histogram appears to be balanced, we will hence proceed to take into account the whole sample (`target.sample = "all"`) when calculating the CATE

> For further discussion of the overlap assumption, please see Imbens and Rubin (2015). In practice, this assumption is often violated due to incorrect modeling decision: for example one covariate may be a deterministic indicator that the example received treatment.

1.  **What is the estimated averate treatment effect in this instance?**

The estimate for the Conditional Averate Treatment Effect is equal to `r cate[1]`, with a variance of `r cate[2]``.

2.  **Is it consistent with your answer in exercise 1.c?**

Our results are consistent with the conclusions of exercise 1.c, as both the analysis show us that the difference between the treatment and control group are not statistically significant.

## Question 2(b)

Now make an analysis of the causal forest results regarding potential heterogeneous treatment effects. Check the results on

### 2(b)(i) The Best Linear Projection

```{r}
blp <- best_linear_projection(tau.forest, covariates[ranked.vars[1:5]])
print(blp)
```

> **What is being performed**: The Best Linear Projection involves regressing the estimated conditional average treatment effects (CATEs) on the covariates. This approach checks whether the heterogeneity captured by the forest is systematically related to the observed covariates. If the coefficients (or the overall fit) are statistically significant, it provides evidence that the treatment effects vary in a predictable way with these covariates.

Interpretation Guidelines:

-   A statistically significant coefficient indicates that a change in the corresponding covariate is associated with a systematic change in the treatment effect.

-   If the overall fit is good, it supports the notion that heterogeneity in treatment effects is predictable from the observed characteristics.

### 2(b)(ii) The Targeting Operator Characteristic

```{r}
samples.by.state <- split(seq_along(final_df$state_id), final_df$state_id)
num.states <- length(samples.by.state)
train <- unlist(samples.by.state[sample(1:num.states, num.states / 2)])

# Training forest (In-bag)
train.forest <- causal_forest(
  covariates[train, ],
  outcome[train],
  treat[train],
  clusters = final_df$state_id[train])

tau.hat.eval <- predict(train.forest,covariates[-train, ])$predictions

# Evaluation forest (Out-of-bag)
eval.forest <- causal_forest(
  covariates[-train, ],
  outcome[-train],
  treat[-train],
  clusters = final_df$state_id[-train])

rate.cate <- rank_average_treatment_effect(eval.forest, tau.hat.eval)
plot(rate.cate, main = "TOC: By decreasing estimated CATE")
```
```{r}
print(rate.cate)
```
```{r}
ci_lower_rate.cate <- rate.cate$estimate - 1.96 * rate.cate$std.err
ci_upper_rate.cate <- rate.cate$estimate + 1.96 * rate.cate$std.err
cat("CATE:", rate.cate$estimate, 
    "\nStd. Error:", rate.cate$std.err,
    "\n95% CI: [", ci_lower_rate.cate, ", ", ci_upper_rate.cate, "]\n")
```

```{r}
#| label: Variable Importance after the split

varimp_as <- variable_importance(eval.forest)
ranked.vars_as <- order(varimp_as, decreasing = TRUE)

colnames(covariates)[ranked.vars_as[1:5]]
```

### 2(b)(iii) Distribution of CATEs

> Plot the distribution of CATEs throughout the distribution of the variables you believe could drive heterogeneity (if you’ll report heterogeneous treatment effects, include graphs for its drivers).

#### i. Religious Adherence

```{r}
driver_s1 <- "religious_adherence"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing religious adherence")
```

```{r}
#| label: Heterogeneity Driver - religious_adherence

scatter_data <- data.frame(
  driver = (covariates[-train, ]$religious_adherence),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Religious Adherence)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### ii. Domestic Violence Rate

```{r}
driver_s1 <- "domestic_violence_rate"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing domestic violence rate")
```

```{r}
#| label: Heterogeneity Driver - domestic_violence_rate

scatter_data <- data.frame(
  driver = (covariates[-train, ]$domestic_violence_rate),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Domestic Violence)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### iii. Women Labour Force Participation

```{r}
driver_s1 <- "women_labor_force_participation"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing women labour force participation")
```

```{r}
#| label: Heterogeneity Driver - women_labor_force_participation

scatter_data <- data.frame(
  driver = (covariates[-train, ]$women_labor_force_participation),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Women labour force participation)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

#### iv. Education Rate

```{r}
driver_s1 <- "education_rate"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing education rate")
```

```{r}
#| label: Heterogeneity Driver - education_rate

scatter_data <- data.frame(
  driver = (covariates[-train, ]$education_rate),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Education rate)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```
#### v. Childcare Availability

```{r}
driver_s1 <- "childcare_availability"

driver <-  covariates[-train, driver_s1]  # Negate if needed for direction of ranking

rate.rel.ad <- rank_average_treatment_effect(eval.forest, -1 * driver, subset = !is.na(driver))

plot(rate.rel.ad, xlab = "Treated fraction", ylab = "Increase in divorce rates", main = "TOC: By increasing education rate")
```

```{r}
#| label: Heterogeneity Driver - childcare_availability

scatter_data <- data.frame(
  driver = (covariates[-train, ]$childcare_availability),
  cate   = tau.hat.eval,
  treat  = treat[-train]
)

scatter_data$treat <- factor(scatter_data$treat,
                             levels = c(0,1),
                             labels = c("Control","Treated"))

ggplot(scatter_data, 
       aes(x = driver, 
           y = cate, 
           colour = treat)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess",
              se     = TRUE, 
              aes(fill = treat)) +   
  scale_colour_manual(values = c("steelblue", "tomato")) +
  scale_fill_manual(  values = c("steelblue", "tomato")) +
  labs(title    = "Relationship between Driver and Estimated Treatment Effects",
       x        = "Driver (Education rate)",
       y        = "Estimated CATE",
       colour   = "Treatment Group",
       fill     = "Treatment Group") +
  theme_minimal()
```

## Question 2(c)

> Discuss your results. Did you find any evidence of heterogeneous treatment effects? Justify your answer based on your output in the previous items.

Points 2(b)(i) and 2(b)(iii) both appear to confirm that heterogeneous treatment effects are present and, in particular, that *religious adherence* plays a fundamental role in driving such heterogeneity; namely, an increase in such driver is associated to a statistically significant reduction in the divorce rate.

## Question 2(d)

> An important aspect in the implementation of causal forests is the use of ”honest trees”, as explained in section 2.4 of Wager and Athey (2017). Explain this procedure and why it is important for our estimation of CATEs. Rerun your analysis without ”honest trees” by selecting `honesty = FALSE`.

### i. Honest Trees Explanations

An “honest” tree enforces a strict sample‐splitting procedure within each tree: the data assigned to a given tree are randomly partitioned into two disjoint halves. One half (the splitting sample) is used solely to choose the tree structure (i.e. where to split on covariates), and the other half (the estimation sample) is used exclusively to estimate treatment effects in each leaf. By decoupling split‐selection from effect‐estimation, honesty prevents the tree from overfitting the noise in the data:

*   **Unbiased effect estimates**: Because the same observations are not used both to pick splits and to estimate effects, the leaf‐level treatment effect estimates are conditionally unbiased.
*   **Valid inference**: Under regularity conditions (Wager & Athey 2017, §2.4), honest forests admit valid confidence intervals for both the ATE and CATEs.
*   **Reduced overfitting**: Honesty forces the forest to generalize rather than tailor splits to idiosyncratic sample noise, which is especially important when assessing heterogeneous effects.

In grf, honesty is the default (honesty = TRUE). It’s a key ingredient for trustworthy inference: without it, forests can exaggerate heterogeneity (by capitalizing on noise) and understate uncertainty.

### ii. Comparison of Results

```{r}
#| label: Estimating the causal forest without honest trees

# Fit the causal forest
tau.forest.hf <- causal_forest(covariates,
                    outcome, 
                    treat,
                    honesty = FALSE
                    )

# Estimate the average treatment effect (ATE)
cate_hf <- average_treatment_effect(tau.forest.hf, 
                                target.sample = "all")
cate_hf

ci_lower <- cate["estimate"] - 1.96 * cate["std.err"]
ci_upper <- cate["estimate"] + 1.96 * cate["std.err"]
cat("ATE:", cate["estimate"], 
    "\nStd. Error:", cate["std.err"],
    "\n95% CI: [", ci_lower, ", ", ci_upper, "]\n")

```

```{r}
blp <- best_linear_projection(tau.forest.hf, covariates[ranked.vars[1:5]])
print(blp)
```

```{r}
samples.by.state <- split(seq_along(final_df$state_id), final_df$state_id)
num.states <- length(samples.by.state)
train <- unlist(samples.by.state[sample(1:num.states, num.states / 2)])

# Training forest (In-bag)
train.forest_hf <- causal_forest(
  covariates[train, ],
  outcome[train],
  treat[train],
  honesty = FALSE,
  clusters = final_df$state_id[train])

tau.hat.eval_hf <- predict(train.forest_hf,covariates[-train, ])$predictions

# Evaluation forest (Out-of-bag)
eval.forest_hf <- causal_forest(
  covariates[-train, ],
  outcome[-train],
  treat[-train],
  honesty = FALSE,
  clusters = final_df$state_id[-train])

rate.cate_hf <- rank_average_treatment_effect(eval.forest_hf, tau.hat.eval_hf)
plot(rate.cate_hf, main = "TOC: By decreasing estimated CATE")
```

1.  **Is your average treatment effect the same?**

The non‐honest forest yields virtually the same ATE as the honest forest. The point estimates are practically identical, their standard errors overlap almost exactly, and the 95% confidence intervals coincide. In other words, disabling honesty did not materially change our estimate of the average effect of unilateral divorce laws on the simulated divorce‐rate change.

2.  **When would you expect this to not be the case?**

When using honest trees versus non-honest trees, we generally expect similar ATE estimates in large samples or when the forest is well-behaved. However, differences can arise in circumstances such as: 1. Small sample sizes: With fewer observations, the split between training and estimation subsamples (required for honest trees) can lead to less precise estimates. The “honesty” constraint might then produce a noticeably different estimate compared to the full sample use when honesty is disabled. 2. Complex or noisy data: When the data exhibits substantial noise or complex heterogeneity, the honest approach—by reducing overfitting—may yield different splits and average effects. In this case, the bias-variance trade-off is shifted such that the imposed honesty can lead to an ATE estimate that diverges from that of the non-honest version. 3. Overfitting concerns: If the non-honest trees are overfitting the data (i.e., tailoring splits too closely to the particular sample noise), the honest trees may provide a more stable, albeit sometimes different, estimate of the ATE by using separate data to decide splits and to estimate treatment effects.

In summary, you would expect the average treatment effect to differ between honest and non-honest trees when the sample size is small or the data is sufficiently noisy/complex so that the benefits of reduced overfitting in honest trees lead to a different overall picture of the treatment effect.
